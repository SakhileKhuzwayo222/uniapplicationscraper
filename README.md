ğŸ“ University Application Scraper (DHET Map Extractor)
![Python](https://img.shields.io/badge

![Selenium](https://img.shields.io/badge/Selenium-Automation-bright

![Status](https://img.shields.io/badge/Status-Active-success.svghttps://img.shields.io/badge/License-MIT-lightgrey.svg Web Scraper** that extracts data on South African higher education institutions from the official DHET (Department of Higher Education and Training) interactive map.

The scraper outputs structured data for use in research, education portals, data analytics, and more.

ğŸ§­ Table of Contents
Overview

Features

Project Structure

Setup & Installation

Usage

Example Output

Logging

Auto-Generated README

License

ğŸ§© Overview
The University Application Scraper automates data extraction from the interactive DHET institutional map to collect:

Institution names

Institution types (TVET colleges, Universities, etc.)

Source URLs for reference

Date and time stamps indicating when the data was scraped

All collected data is saved in a structured JSON format located in the data/ directory for downstream consumption.

âœ¨ Features
âœ… Headless browser automation using Selenium for efficient scraping

âœ… Dynamic extraction of institution markers directly from the DHET map interface

âœ… Robust error handling and retry logic for scraping stability

âœ… JSON output format to facilitate easy integration with other systems

âœ… Detailed logging system to aid debugging and monitor scraping activity

âœ… Auto-generation of README including scraping timestamp and key metrics

ğŸ—‚ï¸ Project Structure
text
uniapplicationscraper/
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ dhet_map_scraper.py       # Extracts institution data from DHET map
â”‚   â”œâ”€â”€ scraper.py                # Main orchestrator combining all scrapers
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py                 # Logging setup and configuration
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_scraper_output.py   # Unit tests for validating scraper output
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sources.json              # Auto-generated JSON containing scraped data
â”‚
â”œâ”€â”€ generate_readme.py            # Automatically rebuilds README with current stats and timestamp
â”œâ”€â”€ requirements.txt              # Python dependencies and versions
â”œâ”€â”€ .gitignore                    # Files and folders excluded from git (venv, logs, etc.)
â””â”€â”€ README.md                     # Project documentation (this file)
âš™ï¸ Setup & Installation
Clone the repository:

bash
git clone https://github.com/yourusername/uniapplicationscraper.git
cd uniapplicationscraper
Create a Python virtual environment and activate it (optional but recommended):

bash
python3 -m venv venv
source venv/bin/activate   # Linux/macOS
venv\Scripts\activate      # Windows
Install the required Python packages:

bash
pip install -r requirements.txt
Ensure you have a compatible version of ChromeDriver or GeckoDriver installed and accessible in your system PATH for Selenium to operate.

ğŸš€ Usage
Run the main scraper:

bash
python scrapers/scraper.py
The output JSON file will be updated in the data/ directory.

ğŸ–¼ï¸ Example Output
A sample entry in data/sources.json looks like:

json
{
  "institution_name": "University of Johannesburg",
  "institution_type": "University",
  "source_url": "https://www.dhet.gov.za/universities/uj",
  "scraped_timestamp": "2025-11-03T08:00:00Z"
}
ğŸ“œ Logging
Logs are saved to logs/ directory with detailed scraper activity, errors, and timestamps. Tail the log file for real-time monitoring.

ğŸ“„ Auto-Generated README
The project includes a script, generate_readme.py, that dynamically updates this README with the latest scrape timestamp and scraper metrics.

ğŸ“ License
This project is licensed under the MIT License. See the LICENSE file for details.

ğŸ’¡ Maintainer
Author: Sakhumuzi Khuzwayo

Purpose: To enable accessible extraction of higher education data in South Africa for research and system interoperability.

